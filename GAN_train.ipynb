{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3FnmK7Jsfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import modules\n",
        "import math\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as utils\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "torch.manual_seed(2)\n",
        "np.random.seed(2)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRqDZl1yCU5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=np.load(\"/content/drive/My Drive/CelebA/image_array_20000.npy\")\n",
        "val_data=np.load(\"/content/drive/My Drive/CelebA/image_fake_array_10000.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6gevF7Mmyjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_array = np.transpose(train_data, (0, 1, 3, 2))\n",
        "train_array = np.transpose(train_array, (0, 2, 1, 3))\n",
        "val_array = np.transpose(val_data, (0, 1, 3, 2))\n",
        "val_array = np.transpose(val_array, (0, 2, 1, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFtmb26bQ4YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = torch.LongTensor(targets)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "#Normalisation of Image\n",
        "transform_norm = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25))])\n",
        "\n",
        "#Loading to a Dataloader; Batch size 50\n",
        "dataset = MyDataset(array, np.zeros((array.shape[0],)), transform=transform_norm)\n",
        "dataloader = DataLoader(dataset, 50, shuffle=True)\n",
        "\n",
        "dataset_val = MyDataset(array_val, np.zeros((array_val.shape[0],)), transform=transform_norm)\n",
        "dataloader_val = DataLoader(dataset_val, 1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnyV3DGbffu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=50):\n",
        "        assert max_size > 0, \"Empty buffer or trying to create a black hole. Be careful.\"\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0, 1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size - 1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRAIHyHlKctu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        global in_features\n",
        "        global out_features\n",
        "        channels = input_shape[0]\n",
        "        out_features = 64\n",
        "        # Initial convolution block\n",
        "\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(channels, out_features, 7),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        in_features = out_features\n",
        "\n",
        "        # Downsampling\n",
        "        for _ in range(2):\n",
        "            out_features *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(num_residual_blocks):\n",
        "            model += [ResidualBlock(out_features)]\n",
        "        \n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class DecoderResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super(DecoderResNet, self).__init__()\n",
        "\n",
        "        global in_features\n",
        "        global out_features\n",
        "        channels = input_shape[0]\n",
        "        model=[]\n",
        "        # Upsampling\n",
        "        for _ in range(2):\n",
        "            out_features //= 2\n",
        "            model += [\n",
        "                nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Output layer\n",
        "        model += [nn.ReflectionPad2d(channels), nn.Conv2d(out_features, channels, 7), nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "##############################\n",
        "#        Discriminator\n",
        "##############################\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        channels, height, width = input_shape\n",
        "\n",
        "        # Calculate output shape of image discriminator (PatchGAN)\n",
        "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Eu6NhPLJVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run Model (Needs all definiations)\n",
        "\n",
        "input_shape = (3, 64, 64)\n",
        "global out_features\n",
        "global in_features\n",
        "G_AB = GeneratorResNet(input_shape, 4)\n",
        "G_AB.cuda()\n",
        "G_AB_d = DecoderResNet(input_shape, 4)\n",
        "G_AB_d.cuda()\n",
        "D_A = Discriminator(input_shape)\n",
        "D_A.cuda()\n",
        "\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_GAN.cuda()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "criterion_identity.cuda()\n",
        "\n",
        "\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_AB_d.parameters()), lr=0.0002, betas=[0.8, 0.9]) #Tune this part\n",
        "optimizer_G.cuda()\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=0.0002, betas=[0.8, 0.9]) #Tune this part\n",
        "optimizer_D_A.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkEP7sSwX2S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def sample_images(batches_done):\n",
        "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
        "    imgs, _ = next(iter(dataloader_val))\n",
        "    G_AB.eval()\n",
        "    G_AB_d.eval()\n",
        "    real_A = Variable(imgs.type(Tensor))\n",
        "\n",
        "    fake_A = G_AB_d(G_AB(real_A))\n",
        "\n",
        "    utils.save_image(fake_A, \"/content/imgs/images%s.png\" % batches_done, normalize=False)\n",
        "    utils.save_image(real_A, \"/content/imgs/images1%s.png\" % batches_done, normalize=False)\n",
        "\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "sample_interval=1000\n",
        "\n",
        "for epoch in range(25):\n",
        "\n",
        "    t_loss=0\n",
        "    id_loss=0\n",
        "    d_loss=0\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Set model input\n",
        "        real_A = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        G_AB.train()\n",
        "        G_AB_d.train()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity loss\n",
        "        a=G_AB(real_A)\n",
        "        print(a.shape)\n",
        "        loss_id_A = criterion_identity(G_AB_d(a), real_A)\n",
        "\n",
        "        loss_identity = (loss_id_A)\n",
        "\n",
        "        # GAN loss\n",
        "        fake_A = G_AB_d(G_AB(real_A))\n",
        "        loss_GAN_AB = criterion_GAN(D_A(fake_A), valid)\n",
        "     \n",
        "        loss_GAN = (loss_GAN_AB)\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = (loss_GAN + 0.8 * loss_identity)/1.8    #Tune this part\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator\n",
        "        # -----------------------\n",
        "\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        loss_real = criterion_GAN(D_A(real_A), valid)\n",
        "        # Fake loss (on batch of previously generated samples)\n",
        "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
        "        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n",
        "        # Total loss\n",
        "        loss_D_A = (loss_real + loss_fake) / 2\n",
        "\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "\n",
        "        # If at sample interval save image\n",
        "        if batches_done % sample_interval == 0:\n",
        "            sample_images(batches_done)\n",
        "        t_loss=loss_G.item()\n",
        "        id_loss=loss_id_A.item()\n",
        "        d_loss=loss_D_A.item()\n",
        "    \n",
        "\n",
        "    print(epoch, \"Total loss:%f, ID loss:%f,  Discriminator loss:%f\" %(t_loss, id_loss, d_loss))\n",
        "    torch.save({'epoch': epoch,\n",
        "                  'model_state_dict': [G_AB.state_dict(), G_AB_d.state_dict(), D_A.state_dict()],\n",
        "                  'optimizer_state_dict': [optimizer_G.state_dict, optimizer_D_A.state_dict()],\n",
        "                  'loss': [loss_G,loss_D_A]}, \"/content/drive/My Drive/DL_GAN_train\"+str(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-IsfhkoX5uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({'epoch': epoch,\n",
        "                  'model_state_dict': [G_AB.state_dict(), G_AB_d.state_dict(), D_A.state_dict()],\n",
        "                  'optimizer_state_dict': [optimizer_G.state_dict, optimizer_D_A.state_dict()],s\n",
        "                  'loss': [loss_G,loss_D_A]}, \"/content/drive/My Drive/DL_GAN_train_master_4LAYER\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}